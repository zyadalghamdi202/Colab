{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zyadalghamdi202/Colab/blob/main/Copy_of_Wetaan_Task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Imports**"
      ],
      "metadata": {
        "id": "Gv0-M_SOx2DH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3V9l23ivqQ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ba49b2b-a4e5-4039-d708-f1d1e7946050"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-04 20:35:53.560 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "!pip install streamlit streamlit-drawable-canvas pyngrok --quiet\n",
        "\n",
        "import joblib\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "import threading\n",
        "\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "from streamlit_drawable_canvas import st_canvas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data**"
      ],
      "metadata": {
        "id": "XFZlDg06x3Zp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "wBQhNv4gxlCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sample Image**"
      ],
      "metadata": {
        "id": "RnFi4nOMx_kC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in trainloader:\n",
        "  print(images.shape)\n",
        "  print(labels.shape)\n",
        "  break\n",
        "\n",
        "\n",
        "plt.imshow(images[0].squeeze(), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.title(f\"Label: {labels[0].item()}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "z16WJOAVxqNx",
        "outputId": "5a7ea0f5-2387-4abe-efc9-48d6569b19f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(1, 8, 3) # (3, 3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(2) # (2, 2) stride = 2\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(1352, 10) # 8 * 13 * 13\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "model = CNN()"
      ],
      "metadata": {
        "id": "S6Jb5pC2u4yL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "epochs=4\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for imgs, labels in trainloader:\n",
        "        preds = model(imgs)\n",
        "        loss = loss_fn(preds, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n"
      ],
      "metadata": {
        "id": "4WRcxWeOvC2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "img = images[63]\n",
        "true_label = labels[63].item()\n",
        "\n",
        "plt.imshow(img.squeeze(), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.title(f\"True Label: {true_label}\")\n",
        "plt.show()\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output = model(img.unsqueeze(0))\n",
        "    predicted_label = torch.argmax(output, dim=1).item()\n",
        "\n",
        "print(f\"Predicted Label: {predicted_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "vQln_iKsupWU",
        "outputId": "c188d4d6-e7cb-4deb-89ac-4fe61ea1ee17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs_batch, labels_batch in testloader:\n",
        "        outputs = model(imgs_batch)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels_batch.size(0)\n",
        "        correct += (predicted == labels_batch).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Accuracy on test set: {accuracy:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wkp4wazButUD",
        "outputId": "641b73aa-15d5-495e-cff2-b5cb025ba818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 97.36%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Bonus Task:**\n",
        "Link the model to an interactive streamlit app :)"
      ],
      "metadata": {
        "id": "1Iydl9hZxpR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(1, 8, 3) # (3, 3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(2) # (2, 2) stride = 2\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(1352, 10) # 8 * 13 * 13\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "model = CNN()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "epochs=2\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for imgs, labels in trainloader:\n",
        "        preds = model(imgs)\n",
        "        loss = loss_fn(preds, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def import_model():\n",
        "  return model\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9z2_q7xHx9G",
        "outputId": "fcf1f789-21dc-41ad-c6ac-a049fe68b8f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "from streamlit_drawable_canvas import st_canvas\n",
        "from model import import_model\n",
        "\n",
        "model = import_model()\n",
        "\n",
        "def preprocess_image(image):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.Resize((28, 28)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    return transform(image).unsqueeze(0)\n",
        "\n",
        "st.title(\"üñåÔ∏è Draw a Digit\")\n",
        "\n",
        "st.markdown(\"ÿßÿ±ÿ≥ŸÖ ÿ±ŸÇŸÖŸãÿß ÿ®ÿÆÿ∑ ŸäÿØŸÉ ŸÅŸä ÿßŸÑŸÖÿ±ÿ®ÿπ ÿ®ÿßŸÑÿ£ÿ≥ŸÅŸÑ ÿ´ŸÖ ÿßŸÜŸÇÿ± ÿÆÿßÿ±ÿ¨ ÿßŸÑŸÖÿ±ÿ®ÿπ ŸÑÿ™ÿ®ÿØÿ£ ÿßŸÑÿ™ŸÜÿ®ÿ§.\")\n",
        "\n",
        "# Ÿàÿßÿ¨Ÿáÿ© ÿßŸÑÿ±ÿ≥ŸÖ\n",
        "canvas_result = st_canvas(\n",
        "    fill_color=\"white\",\n",
        "    stroke_width=10,\n",
        "    stroke_color=\"white\",\n",
        "    background_color=\"black\",\n",
        "    width=200,\n",
        "    height=200,\n",
        "    drawing_mode=\"freedraw\",\n",
        "    key=\"canvas\"\n",
        ")\n",
        "\n",
        "if canvas_result.image_data is not None:\n",
        "    image = Image.fromarray((canvas_result.image_data[:, :, 0]).astype(np.uint8))\n",
        "    resized_image = image.resize((28, 28))\n",
        "\n",
        "    st.image(resized_image, caption=\"Resized Input\", width=150)\n",
        "\n",
        "    input_tensor = preprocess_image(resized_image)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        pred = torch.argmax(output, dim=1).item()\n",
        "\n",
        "    st.success(f\"Predicted Digit: {pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoM7zFoEl8xp",
        "outputId": "c532f95d-8740-49e7-a70d-7bacb82e9097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2zK6TG51lreSfp7dTwEBGmJz8Mh_5qw8yxDoTLULpfYearqyc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Gr5iZbDmsOX",
        "outputId": "db6dae59-246a-4878-e198-ba5c2ae6773a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!which streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odeOCrbrtW_D",
        "outputId": "1a699378-771b-46c7-b0ce-1b1583a18b7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/streamlit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8501, \"http\")\n",
        "print(f\"Streamlit URL: {public_url}\")\n",
        "\n",
        "!streamlit run app.py &\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LE_ODxtmtcxz",
        "outputId": "3bcdf2b8-6ce2-42d8-aa25-3fe47e03de07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit URL: NgrokTunnel: \"https://037a-35-229-202-95.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.229.202.95:8501\u001b[0m\n",
            "\u001b[0m\n",
            "2025-07-04 21:27:19.686 MediaFileHandler: Missing file 8f45de48a88e0c40a798d542407e023766dc52e5f3b4f88f403d874d.jpg\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 348, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/runtime/memory_media_file_storage.py\", line 140, in get_file\n",
            "    return self._files_by_id[file_id]\n",
            "           ~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
            "KeyError: '8f45de48a88e0c40a798d542407e023766dc52e5f3b4f88f403d874d'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/server/media_file_handler.py\", line 95, in validate_absolute_path\n",
            "    self._storage.get_file(absolute_path)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/runtime/memory_media_file_storage.py\", line 142, in get_file\n",
            "    raise MediaFileStorageError(\n",
            "streamlit.runtime.media_file_storage.MediaFileStorageError: Bad filename '8f45de48a88e0c40a798d542407e023766dc52e5f3b4f88f403d874d.jpg'. (No media file with id '8f45de48a88e0c40a798d542407e023766dc52e5f3b4f88f403d874d')\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}